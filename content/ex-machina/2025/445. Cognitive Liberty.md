---
title: Cognitive Liberty
tags:
  - data_governance
  - data_protection
published: 2025-09-24
urlCanonical: https://exmachina.in/24/09/2025/cognitive-liberty/
urlSecondary: https://www.livemint.com/opinion/online-views/artificial-intelligence-data-protection-law-india-neuralink-ethics-cognitive-brain-privacy-ai-11758525049864.html
categories:
  - article
writingStatus: published
created: 2025-09-28T21:27
publication: Ex Machina

date: 2025-09-24
---


_As the technology to collect neural information directly from our brains starts to become commercially viable, we need to think deeply about the social and ethical implications of this. Apart from just data protection we may need a broader articulation of cognitive liberty._

---

As regular readers of Ex Machina know, I have been waiting more than a decade for India to pass a comprehensive data protection law. Despite recent statements by the government suggesting that rules under the 2023 Digital Personal Data Protection law are imminent, I have heard these promises so many times over the years that I have resigned myself to only believing it when I see it.

Meanwhile, technology has evolved at a blistering pace. When I first started working on a data protection law, I thought a notice and consent regime would be enough. I was convinced that so long as we offered individuals a meaningful way to exercise control over what was done with their data, they would have all the protection they needed. But with the advent of Big Data, it was clear that traditional notions of notice and consent were becoming increasingly meaningless. Not only was data being collected in so many different ways and by so many different entities that it had become impossible to keep track of, the ways in which this data was being used had become so complex that even the most digitally savvy among us were hard pressed to appreciate the consequences of our decisions.

Artificial intelligence (AI) has made things worse. Scant heed was paid to the data protection principles of prior consent and specific use when powerful AI systems were built. What’s more, since our interaction with AI systems takes place through chat interfaces, this has encouraged a level of intimacy that makes it easier for us to share more than we otherwise would, with little thought given to the consequences. But as bad as things are, they are about to get worse.

### Neuro Data

In her book [The Battle for Your Brain](https://www.amazon.com/Battle-Your-Brain-Defending-Neurotechnology/dp/1250272955), Nita Farahany discusses the latest advances in neuro-technology and shows how close it is to widespread commercial availability. Affordable brain sensors can already collect data on our attention, fatigue, emotions and even our subconscious reactions directly from our brains. If we were worried about algorithms drawing inferences from our online behaviour, those fears pale in comparison with the harms that could result when insights about us are drawn directly from our brains.

It is China (not the Western world) that is at the vanguard of these technological developments. Railway drivers on the Beijing-Shanghai line (arguably the busiest high-speed link in the world) are already required to [wear EEG devices](https://pmc.ncbi.nlm.nih.gov/articles/PMC7773904/) that collect real-time brain data in order to monitor their alertness levels. Factory workers in government-controlled facilities have to wear similar devices to monitor their productivity and current emotional states. Neural monitoring has already moved out of the realm of science fiction into everyday workspaces.

Very soon, these technologies will be deployed more widely around the world. It will likely start with high-risk job environments, where they will be used as a necessary measure to ensure safety. 

But once the technology has proven itself, it will be promoted as a tool to improve productivity and efficiency. Soon, neural surveillance will become socially acceptable, both as a safety measure as well as a tool for improving our focus and managing emotions in a variety of different contexts.

When this happens, the technology will cross over into the wellness space. Around the world, EEG headsets are being advertised as brain-training devices that customers can use to modify their mental states. Companies like [Neuphony](https://www.neuphony.com/) are already offering neurofeedback headbands in India, aimed at enhancing cognition and improving brain health. Non-invasive vagus nerve stimulation is being promoted as a way to reduce stress and improve sleep. Minimally invasive brain control interfaces are now being discussed in the context of augmenting cognition.

### Cognitive Liberty

But despite the many benefits that these devices have to offer, their adoption is likely to come at a high cost. Neural data is perhaps the most intimate form of personal data that is being processed today. The harms that could result if it is used maliciously—for coercion and manipulation or to shape attention and influence decisions—are likely to be far worse than anything we have seen so far.

These concerns have not gone unnoticed. Several states in the US have proposed new regulations to address the privacy concerns that arise out of the use of this technology—and the fact that users are simply incapable of deciding what neural information they should disclose, let alone understanding the extent to which what they have provided can be decoded or understood, currently or in the future. Chile has even enshrined neuro-rights in its constitution.

What is at stake, Farahany argues, is our cognitive liberty, a term she uses to encompass all the challenges of mental privacy and freedom of thought that these new technologies pose. Mental privacy extends to our subconscious reactions, emotions and thoughts—aspects of our personality that we have believed will remain deeply private. This curtails our freedom of thought as it exposes our inner beliefs and moral convictions in ways that affect our ability to engage with the full diversity of modern society.

India needs to think about what a cognitive liberty framework would look like. It needs to recognize brain data as fundamental to human autonomy, so we can regulate how it is collected and used. We need to ensure that India’s long awaited data protection regime addresses these concerns.